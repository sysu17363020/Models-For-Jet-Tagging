{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69aeaf81-607b-4d55-9e77-be267ac08479",
   "metadata": {},
   "source": [
    "# Conditional L-GATr Quickstart\n",
    "# [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/heidelberg-hepml/lgatr/blob/main/examples/demo_conditional_lgatr.ipynb)\n",
    "\n",
    "This tutorial is a quick introduction into using conditional L-GATr models, building on the simpler [non-conditional L-GATr](https://github/heidelberg-hepml/lgatr/blob/main/examples/demo_lgatr.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58232c6b-85e1-4e48-857b-24995368ef6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the lgatr package\n",
    "%pip install lgatr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad94a506-afb2-47ad-9c44-dbdf7f1081f1",
   "metadata": {},
   "source": [
    "In addition to the normal `LGATr` encoder module `lgatr`, we now create a `ConditionalLGATr` decoder module `conditional_lgatr`. We will first process the condition with the `lgatr` encoder, and then process it together with the main data using the `conditional_lgatr`.\n",
    "Note that we set `out_mv_channels=hidden_mv_channels`, `out_s_channels=hidden_s_channels` for `LGATr`, and `condition_mv_channels=hidden_mv_channels`, `condition_s_channels=hidden_s_channels` for `ConditionalLGATr`. This is because we do not want to enforce a bottleneck for the condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e99acac-8bd8-4c8a-a770-9f9619a3d1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct LGATr and ConditionalLGATr modules\n",
    "from lgatr import LGATr, ConditionalLGATr\n",
    "\n",
    "attention = dict(num_heads=2)\n",
    "crossattention = dict(num_heads=2)\n",
    "mlp = dict()\n",
    "lgatr = LGATr(\n",
    "   in_mv_channels=1,\n",
    "   out_mv_channels=8,\n",
    "   hidden_mv_channels=8,\n",
    "   in_s_channels=0,\n",
    "   out_s_channels=16,\n",
    "   hidden_s_channels=16,\n",
    "   attention=attention,\n",
    "   mlp=mlp,\n",
    "   num_blocks=2,\n",
    ")\n",
    "conditional_lgatr = ConditionalLGATr(\n",
    "   in_mv_channels=1,\n",
    "   condition_mv_channels=8,\n",
    "   out_mv_channels=1,\n",
    "   hidden_mv_channels=8,\n",
    "   in_s_channels=0,\n",
    "   out_s_channels=0,\n",
    "   condition_s_channels=16,\n",
    "   hidden_s_channels=16,\n",
    "   attention=attention,\n",
    "   crossattention=crossattention,\n",
    "   mlp=mlp,\n",
    "   num_blocks=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5437a87b-26a2-4cba-bbee-5c50e777cbbb",
   "metadata": {},
   "source": [
    "Similar to the `LGATr` notebook, we test our model on toy data of shape `p.shape = (128, 20, 1, 4)`; for batch size 128, 20 particles per jet, 1 four-momentum per particle, and 4 numbers for the four-momentum. We add another set of 40 particles as the condition, `p_c.shape = (128, 40, 1, 4)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "739008ef-6a14-4f8e-a1d8-6e1e79edb4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 20, 1, 4]) torch.Size([128, 40, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "# generate toy data\n",
    "import torch\n",
    "p3 = torch.randn(128, 20, 1, 3)\n",
    "mass = 1\n",
    "E = (mass**2 + (p3**2).sum(dim=-1, keepdim=True))**0.5\n",
    "p = torch.cat((E, p3), dim=-1)\n",
    "p3_c = torch.randn(128, 40, 1, 3)\n",
    "E_c = (mass**2 + (p3_c**2).sum(dim=-1, keepdim=True))**0.5\n",
    "p_c = torch.cat((E_c, p3_c), dim=-1)\n",
    "print(p.shape, p_c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0022a86-86ab-435b-8b91-9c1c12569f66",
   "metadata": {},
   "source": [
    "We now embed the four-momentum and the condition into multivectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6753009e-5ac9-427a-9a8e-1c258c05835f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 20, 1, 16]) torch.Size([128, 40, 1, 16])\n"
     ]
    }
   ],
   "source": [
    "from lgatr.interface import embed_vector, extract_scalar\n",
    "multivector = embed_vector(p)\n",
    "multivector_condition = embed_vector(p_c)\n",
    "print(multivector.shape, multivector_condition.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e05b73c-69ca-4adc-aec4-45f79cf0a17f",
   "metadata": {},
   "source": [
    "We can now process the data with our conditional L-GATr model. First, we process the condition with the `lgatr` encoder. We obtain an embedding of the condition in a high-dimensional latent space. We then process this condition together with the main network input using the `conditional_lgatr` decoder. Finally, we extract the scalar part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0e61ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 40, 8, 16]) torch.Size([128, 40, 16])\n",
      "torch.Size([128, 20, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# encoder (lgatr)\n",
    "condition_mv, condition_s = lgatr(multivectors=multivector_condition, scalars=None)\n",
    "print(condition_mv.shape, condition_s.shape)\n",
    "\n",
    "# decoder (conditional_lgatr)\n",
    "output_mv, output_s = conditional_lgatr(\n",
    "    multivectors=multivector,\n",
    "    multivectors_condition=condition_mv,\n",
    "    scalars_condition=condition_s,\n",
    ")\n",
    "out = extract_scalar(output_mv)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53356edb-8a63-4008-91cc-781afbd74e0c",
   "metadata": {},
   "source": [
    "Thats it, now you're ready to build your own `ConditionalLGATr` model! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
